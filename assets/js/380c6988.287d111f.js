"use strict";(self.webpackChunkslop_site=self.webpackChunkslop_site||[]).push([[9088],{3905:(e,n,t)=>{t.d(n,{Zo:()=>c,kt:()=>g});var o=t(7294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);n&&(o=o.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,o)}return t}function s(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function i(e,n){if(null==e)return{};var t,o,a=function(e,n){if(null==e)return{};var t,o,a={},r=Object.keys(e);for(o=0;o<r.length;o++)t=r[o],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(o=0;o<r.length;o++)t=r[o],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var l=o.createContext({}),p=function(e){var n=o.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):s(s({},n),e)),t},c=function(e){var n=p(e.components);return o.createElement(l.Provider,{value:n},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var n=e.children;return o.createElement(o.Fragment,{},n)}},h=o.forwardRef((function(e,n){var t=e.components,a=e.mdxType,r=e.originalType,l=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),u=p(t),h=a,g=u["".concat(l,".").concat(h)]||u[h]||d[h]||r;return t?o.createElement(g,s(s({ref:n},c),{},{components:t})):o.createElement(g,s({ref:n},c))}));function g(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var r=t.length,s=new Array(r);s[0]=h;var i={};for(var l in n)hasOwnProperty.call(n,l)&&(i[l]=n[l]);i.originalType=e,i[u]="string"==typeof e?e:a,s[1]=i;for(var p=2;p<r;p++)s[p]=t[p];return o.createElement.apply(null,s)}return o.createElement.apply(null,t)}h.displayName="MDXCreateElement"},9738:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>u,frontMatter:()=>r,metadata:()=>i,toc:()=>p});var o=t(7462),a=(t(7294),t(3905));const r={sidebar_position:3},s="Adding Types / Operations",i={unversionedId:"Extending/type-operations",id:"Extending/type-operations",title:"Adding Types / Operations",description:"As can be seen in the Design Approach section, types can be defined using regular",source:"@site/docs/Extending/type-operations.md",sourceDirName:"Extending",slug:"/Extending/type-operations",permalink:"/slop-site/docs/Extending/type-operations",draft:!1,editUrl:"https://gitlab.com/tronied/slop/docs/Extending/type-operations.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Grammar",permalink:"/slop-site/docs/Extending/grammar"},next:{title:"Custom Operators",permalink:"/slop-site/docs/Extending/custom-operators"}},l={},p=[{value:"Type Operations",id:"type-operations",level:2}],c={toc:p};function u(e){let{components:n,...t}=e;return(0,a.kt)("wrapper",(0,o.Z)({},c,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"adding-types--operations"},"Adding Types / Operations"),(0,a.kt)("p",null,"As can be seen in the ",(0,a.kt)("a",{parentName:"p",href:"#design-approach"},"Design Approach")," section, types can be defined using regular\nexpressions or grammar. If the type you are writing is simple and represents a primitive type or object\nthen regular expressions would be best. However, if you are wanting to customise how your type is defined\nor interact with other types then use grammar."),(0,a.kt)("p",null,"Take the original example which is a simple long type. We can see by the regular expression ",(0,a.kt)("inlineCode",{parentName:"p"},"(^(-?[0-9]+)L)"),"\nthat a long can be defined as either positive or negative if the number itself is followed by an 'L' character.\nSo far so simple, however things get more complicated when it comes to collections. Let's say we wanted to define a\nMap type where one or more key / value pairs are separated by '->' syntax and surrounded by curly braces. We\ncould define this by using the following ",(0,a.kt)("inlineCode",{parentName:"p"},"{((.+?)->(.+?),?)+}"),". However say we have ",(0,a.kt)("inlineCode",{parentName:"p"},"{1->1,2->2 + 2,3->3}"),"\nin an expression, because we've got multiple embedded groups we run into issues with them either not knowing\nwhen to stop (overly greedy) or not being greedy enough due to the syntax."),(0,a.kt)("p",null,"This is where defining the pattern with grammar is useful as it is designed to handle complex structures. It\nalso allows better handling of individual tokens in simplistic form. Let's use the Map as an example which can\nbe defined as the following ",(0,a.kt)("inlineCode",{parentName:"p"},"'{' ( ( val '->' expr ','? ) )+ '}'"),". This can be broken down:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"'{'   = Starting syntax curly brace\n(     = Capture group start\n(     = Capture group start (Multiple embedded grammar groups used for collection element separation)\nval   = Single capture token (Key must be defined as a single value and cannot be the result of an \n        operation)\n'->'  = Syntax key / value pair separator\nexpr  = Multiple token capture group (could be the result of an operation e.g. 1 + 1)\n','   = A syntax comma separating key / value pairs\n?     = Makes the preceding tag (comma) optional as a map could be defined as a single key / value \n        e.g. {1->1}\n)     = Closing capture group\n)     = Closing capture group (Each capture group gets mapped to a TokenGroup handled by the \n        ``process`` method)\n+     = Signifies that there could be one or more of the preceding group (in this case key / value \n        pairs)\n'}'   = Closing syntax curly brace\n")),(0,a.kt)("p",null,"It is important to understand when and where methods within a Token get called: "),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Pattern tokens are initially generated and stored against all token types registered in the configuration class.\nDepending on the pattern type (",(0,a.kt)("inlineCode",{parentName:"li"},"getPatternType")," method) this determines whether these are created by the Grammar\nLexer or deferred to the regex matchers during the Expression String lexing stage."),(0,a.kt)("li",{parentName:"ol"},"As each literal value is read from the Expression String, matches may occur against registered Token classes and\ntheir pattern tokens. If two or more matches are found then it looks ahead in the expression to make a best-guess at\na matching Token. In the case where there is no clear choice an exception is thrown."),(0,a.kt)("li",{parentName:"ol"},"Once the matching Token has been identified, a new instance of it is created by calling the ",(0,a.kt)("inlineCode",{parentName:"li"},"createToken(String value)"),"\nmethod. This creates a new version of the Token and clones all the pattern tokens and settings from the match."),(0,a.kt)("li",{parentName:"ol"},"During the lexing phase, the matched Token will be added to the top of the stack so that if it was declared within\nthe body of another token or has itself other tokens declared in its body, these can easily be managed. Each\nToken keeps track of its position with new items being added to the stack at that position until they are deemed\ncomplete and added as a child token to the new stack head."),(0,a.kt)("li",{parentName:"ol"},"As more tokens / syntax are read from the expression, the position of the matched token is progressed accordingly\nand tokens are added to Token Groups matching the position in which they're added (see ",(0,a.kt)("inlineCode",{parentName:"li"},"MyToken.getTokenGroups()"),")."),(0,a.kt)("li",{parentName:"ol"},"Once the lexing phase is complete, the hierarchical list of tokens is sent to the Parser for resolution. Each\nToken is responsible for resolving its own result in tandem with the Parser when its ",(0,a.kt)("inlineCode",{parentName:"li"},"process()")," method is called.\nChild tokens (located in the token groups) can then be used to affect behaviour or resolve values. ")),(0,a.kt)("p",null,"Let's take the simple conditional statement as an example and perform a breakdown:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-java"},'//...\n@Override\npublic String getPattern() {\n    //condition ? trueResult : falseResult\n    return "expr \'?\' expr \':\' expr";\n}\n\n@Override\npublic List<Token<?>> process(SLOPParser parser, SLOPContext context, SLOPConfig config) {\n    //Expect that there are 3 tokens groups representing the condition and true / false token groups\n    if (getTokenGroups().size() < 3) {\n        throw new ParserException(String.format("Condition does not have required arguments to execute. Expecting " +\n                "condition (%s), trueResult (%s) and falseResult (%s)", getTokenGroups().get(0), getTokenGroups().get(1),\n                getTokenGroups().get(2)));\n    }\n    //Evaluate the condition using the tokens found in the first token group\n    Token<?> conditionResult = parser.processExpression(getTokenGroups().get(0).getTokens(), context);\n    //If the condition is not a Boolean then throw an error i.e. "1 + 2 ? 3 : 4"\n    if (!(conditionResult instanceof BooleanToken)) {\n        throw new ParserException(String.format("Expected a boolean result from condition \'%s\'. Possible invalid " +\n                        "condition specified", getTokenGroups().get(0)));\n    }\n    //Execute the relevant set of tokens based on the condition result\n    return Collections.singletonList((((BooleanToken) conditionResult).getValue()) ?\n            parser.processExpression(getTokenGroups().get(1).getFlatTokens(), context) :\n            parser.processExpression(getTokenGroups().get(2).getFlatTokens(), context));\n}\n//...\n')),(0,a.kt)("p",null,"The pattern is very simple consisting of 3 expressions (one or more tokens) with the condition and two possible results. Looking\nat the ",(0,a.kt)("inlineCode",{parentName:"p"},"process")," method we can see an initial check is made to ensure that there are 3 defined token groups, otherwise an\nexception is thrown. This is part of the role of the Parser with each Token responsible for validating its content. If we\nmatch up the token groups against the capture groups defined in the grammar string, we get the following:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"getTokenGroups() Collection:\n    [0] Condition\n    [1] True Result\n    [2] False Result\n")),(0,a.kt)("p",null,"The first task will then be to resolve the value of the conditional part which is found at position 0 of the token groups:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-java"},"    //Evaluate the condition using the tokens found in the first token group\n    Token<?> conditionResult = parser.processExpression(getTokenGroups().get(0).getTokens(), context);\n")),(0,a.kt)("p",null,"As mentioned before, the tokens are passed back to the Parser for resolution as each token will be responsible for resolving\nits own value. The parser also handles the type operations in any expression e.g. A + B. Once a result has been returned from\nthe parser, in this case it is assigned to a new token called ",(0,a.kt)("inlineCode",{parentName:"p"},"conditionResult"),". Tokens are stateless by default and so we\nhave to check it conforms to the type we are wanting, which in the case of a condition is a Boolean. If not we throw an exception:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-java"},'    //If the condition is not a Boolean then throw an error i.e. "1 + 2 ? 3 : 4"\n    if (!(conditionResult instanceof BooleanToken)) {\n        throw new ParserException(String.format("Expected a boolean result from condition \'%s\'. Possible invalid " +\n                        "condition specified", getTokenGroups().get(0)));\n    }\n')),(0,a.kt)("p",null,"Finally we can evaluate our condition and resolve the associate set of tokens and return the result:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-java"},"    //Execute the relevant set of tokens based on the condition result\n    return Collections.singletonList((((BooleanToken) conditionResult).getValue()) ?\n            parser.processExpression(getTokenGroups().get(1).getFlatTokens(), context) :\n            parser.processExpression(getTokenGroups().get(2).getFlatTokens(), context));\n")),(0,a.kt)("p",null,"Getting back to our Map type, although it is a bit more complicated it uses the same principles. We verify the data\nand perform certain actions against a set of tokens or resolve their values. In this case there is no behaviour as it\nis simply there to store data, so the majority of the ",(0,a.kt)("inlineCode",{parentName:"p"},"process")," method is there to resolve and translate those values\nto a native map:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-java"},'@NoArgsConstructor\npublic class MapToken extends Token<Map<Token<?>, Token<?>>> {\n\n    public MapToken(Map<Token<?>, Token<?>> values) {\n        super("Map", values);\n    }\n\n    @Override\n    public Token<Map<Token<?>, Token<?>>> createToken(String value) {\n        MapToken source = new MapToken(new HashMap<>());\n        Token<Map<Token<?>, Token<?>>> result = cloneDefaultProperties(source);\n        result.setValue(source.getValue());\n        return result;\n    }\n\n    @Override\n    public PatternType getPatternType() {\n        return PatternType.GRAMMAR;\n    }\n\n    @Override\n    public String getPattern() {\n        //One or more key / value pairs separated by \'->\' and wrapped in curly braces e.g. {1->1,2->2}\n        return "\'{\' ( ( val \'->\' expr \',\'? ) )+ \'}\'";\n    }\n\n    @Override\n    public List<Token<?>> process(SLOPParser parser, SLOPContext context, SLOPConfig config) {\n        Map<Token<?>, Token<?>> aMap = Objects.isNull(getValue()) ? new HashMap<>() : getValue();\n        //Handle blank initializer\n        if (!getTokenGroups().isEmpty()) {\n            //Scan the resulting token groups and unwrap as much as possible to make handling easier\n            Token<?> mapStructure = getTokenGroups().get(0).unwrapKeepStructure(getTokenGroups().get(0));\n            if (mapStructure instanceof TokenGroup) {\n                /* Expect map structure to take form of a TokenGroup with child TokenGroups of Key / Value pairs.\n                 * If this is not the case then wrap the result in another TokenGroup as the unwrap has gone too far */\n                if (((TokenGroup) mapStructure).getTokens().stream().anyMatch(t -> !(t instanceof TokenGroup))) {\n                    mapStructure = new TokenGroup(Collections.singletonList(mapStructure));\n                }\n                ((TokenGroup) mapStructure).getTokens()\n                        .forEach(tg -> {\n                            //Although the key is restricted to a single token, resolve it anyway as it could need resolving\n                            Token<?> key = ((TokenGroup) tg).getTokens().get(0);\n                            key = parser.processExpression(key instanceof TokenGroup ?\n                                    ((TokenGroup) key).getTokens() : Collections.singletonList(key), context);\n                            Token<?> value = ((TokenGroup) tg).getTokens().get(1);\n                            value = parser.processExpression(value instanceof TokenGroup ?\n                                    ((TokenGroup) value).getTokens() : Collections.singletonList(value), context);\n                            //Add the resolved values to resulting map\n                            aMap.put(key, value);\n                        });\n            } else {\n                throw new ParserException(String.format("Cannot initialize map with token of type \'%s\'",\n                        mapStructure.getClass().getSimpleName()));\n            }\n        }\n        if (Objects.isNull(getValue())) setValue(aMap);\n        return Collections.singletonList(this);\n    }\n\n    @Override\n    public String toString() {\n        if (Objects.isNull(getValue())) {\n            throw new ParserException("Map values have not been processed yet");\n        }\n        String result = getValue().entrySet().stream()\n                .map(e -> e.getKey().getValue().toString() + " -> " + e.getValue().getValue().toString())\n                .collect(Collectors.joining(", "));\n        return "MapToken{values = [" +\n                result +\n                "]}";\n    }\n}\n')),(0,a.kt)("p",null,"To register / declare the type in the configuration, simply create a new instance and add to the tokenHandler collection\nin the configuration class:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-java"},"    private void initTokenHandlers() {\n        //...\n        \n        //Language literals / supported types\n        //...        \n        tokenHandlers.add(new MapToken());\n        //...\n    }\n")),(0,a.kt)("p",null,"This allows us to now define a Map using ",(0,a.kt)("inlineCode",{parentName:"p"},"{Key->Value,Key->Value,...}"),". If you enable unsafe operations\n(See ",(0,a.kt)("a",{parentName:"p",href:"#configuration-class"},"Configuration Class"),"), you can add, remove or fetch values directly using the\nMap Java class implementation e.g."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'> {1->"first",2->"second"}.get(1)\nResult: "first" (Time taken: 1ms)\n')),(0,a.kt)("p",null,"The maps are not type specific and can support anything you throw at it:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'> myVar = {"first"->1,2->"second"}\n> myVar.put("third",3)\n> myVar\nResult: {"first"=1, 2="second", "third"=3} (Time taken: 1ms)\n> myVar.remove("third")\n> myVar\nResult: {"first"=1, 2="second"} (Time taken: 1ms)\n')),(0,a.kt)("h2",{id:"type-operations"},"Type Operations"),(0,a.kt)("p",null,"Operation support can be added for your type to allow more ease of use when dealing with the types natively.\nFor example, we can define the following TypeOperation implementation for our new Map type:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-java"},'/**\n * Handles Map operations including add and subtract with the latter supporting both Map and Lists. The\n * result is returned as a MapToken.\n */\npublic class MapOperation implements TypeOperation {\n\n    /**\n     * See {@link TypeOperation#canHandle(Token, OperatorToken, Token) canHandle}\n     */\n    @Override\n    public boolean canHandle(Token<?> first, OperatorToken operator, Token<?> second) {\n        return first.is(Map.class) && (second.is(Map.class) || second.is(List.class));\n    }\n\n    /**\n     * See {@link TypeOperation#handleCustomOperator(Token, OperatorToken, Token) handleCustomOperator}\n     */\n    @Override\n    public <T> T handleCustomOperator(Token<?> first, OperatorToken operator, Token<?> second) {\n        throw new ParserException(String.format("Unable to handle Map operation with operator \'%s\'",\n                operator.getValue()));\n    }\n\n    /**\n     * See {@link TypeOperation#process(SLOPConfig, Token, OperatorToken, Token) process}\n     */\n    @Override\n    @SuppressWarnings("unchecked")\n    public Token<?> process(SLOPConfig config, Token<?> first, OperatorToken operator, Token<?> second) {\n        OperatorHandler handler = config.getOperatorHandler();\n        //We can suppress warnings here as we\'ve already checked the contained token\n        Map<Token<?>,Token<?>> original = first.getValue(Map.class);\n        if (second.is(Map.class)) {\n            Map<Token<?>,Token<?>> compare = second.getValue(Map.class);\n            return handleMapOperations(handler, original, compare, operator,\n                    () -> handleCustomOperator(first, operator, second));\n        } else {\n            List<Token<?>> compare = second.getValue(List.class);\n            return handleListOperations(handler, original, compare, operator,\n                    () -> handleCustomOperator(first, operator, second));\n        }\n    }\n\n    @SuppressWarnings("unchecked")\n    private Token<?> handleMapOperations(OperatorHandler handler, Map<Token<?>,Token<?>> original,\n                                         Map<Token<?>,Token<?>> compare, OperatorToken operator,\n                                         CustomOperation customOp) {\n        final Map<Token<?>, Token<?>> result;\n        switch (handler.getOpType(operator)) {\n            /* Adds two maps together e.g. {1:1,2:2} + {3:3,4:4} = {1:1,2:2,3:3,4:4}. Note that if there is a key\n             * which already exists in the left-side map then it will be overwritten by that on the right e.g.\n             * {1:1,2:2} + {1:2,3:3} = {1:2,2:2,3:3} */\n            case ADD:\n                result = new HashMap<>(original);\n                result.putAll(compare);\n                break;\n            /* Subtracts a map from the other e.g. [1:1,2:2,3:3] - [2:2,3:3] = [1:1]. Please note items are only removed\n             * if their key and values match. There if you did [1:1] - [1:3], you\'d still result in the original [1:1] */\n            case SUBTRACT:\n                result = new HashMap<>(original);\n                List<Token<?>> keysToRemove = original.keySet().stream()\n                        .filter(compare.keySet()::contains)\n                        .collect(Collectors.toList());\n\n                keysToRemove.forEach(kr -> {\n                    //Only remove those with matching values too\n                    if (result.get(kr).equalsValue(compare.get(kr))) {\n                        result.remove(kr);\n                    }\n                });\n                break;\n            default: result = (Map<Token<?>, Token<?>>) customOp.handleCustomOp();\n        }\n        return new MapToken(result);\n    }\n\n    @SuppressWarnings("unchecked")\n    private Token<?> handleListOperations(OperatorHandler handler, Map<Token<?>,Token<?>> original,\n                                         List<Token<?>> compare, OperatorToken operator,\n                                         CustomOperation customOp) {\n        Map<Token<?>, Token<?>> result;\n        if (handler.getOpType(operator) == OperatorType.SUBTRACT) {\n            /* Subtracts the matching keys present in the right-side list from the left-side map */\n            List<Token<?>> keysToRemove = original.keySet().stream()\n                    .filter(compare::contains)\n                    .collect(Collectors.toList());\n            keysToRemove.forEach(original::remove);\n            result = original;\n        } else {\n            result = (Map<Token<?>, Token<?>>) customOp.handleCustomOp();\n        }\n        return new MapToken(result);\n    }\n\n    /**\n     * A simple functional interface to avoid having to pass multiple parameters to perform the same\n     * call for both right-side Map and Lists if the default case is triggered.\n     */\n    @FunctionalInterface\n    private interface CustomOperation {\n        Token<?> handleCustomOp();\n    }\n}\n')),(0,a.kt)("p",null,"Although this looks quite complicated, let's start by breaking each stage down and explaining what each part does.\nAs the parser processes the tokens, it looks for certain patterns like that of two Tokens surrounding an OperatorToken.\nIn this scenario, it will fetch all of the declared TypeOperation classes and search for a match using the ",(0,a.kt)("inlineCode",{parentName:"p"},"canHandle"),"\nmethod by passing it all the tokens involved in the operation. In the case of our MapOperation class, we are doing the\nfollowing:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-java"},"@Override\npublic boolean canHandle(Token<?> first, OperatorToken operator, Token<?> second) {\n    return first.is(Map.class) && (second.is(Map.class) || second.is(List.class));\n}\n")),(0,a.kt)("p",null,"In this case we're declaring that we only support a map type on the left-side but both a map or list on the right-side.\nIf it found that the types do match then a call to the ",(0,a.kt)("inlineCode",{parentName:"p"},"process")," method is made:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-java"},'@Override\n@SuppressWarnings("unchecked")\npublic Token<?> process(SLOPConfig config, Token<?> first, OperatorToken operator, Token<?> second) {\n    OperatorHandler handler = config.getOperatorHandler();\n    //We can suppress warnings here as we\'ve already checked the contained token\n    Map<Token<?>,Token<?>> original = first.getValue(Map.class);\n    if (second.is(Map.class)) {\n        Map<Token<?>,Token<?>> compare = second.getValue(Map.class);\n        return handleMapOperations(handler, original, compare, operator,\n                () -> handleCustomOperator(first, operator, second));\n    } else {\n        List<Token<?>> compare = second.getValue(List.class);\n        return handleListOperations(handler, original, compare, operator,\n                () -> handleCustomOperator(first, operator, second));\n    }\n}\n')),(0,a.kt)("p",null,"In the above case we're first fetching the OperatorHandler class from the config. This allows us to compare the passed\noperator against the registered ones we have and perform an easy (and readable) switch statement to handle each. In\nthis case since we have to handle both right-side list and map types, we first check and call a different method to\nhandle each (",(0,a.kt)("inlineCode",{parentName:"p"},"handleMapOperations")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"handleListOperations"),"). We are also passing in a method reference to\nhandle any unsupported operators that we encounter. In this case though we are just throwing an exception if that\noccurs in the ",(0,a.kt)("inlineCode",{parentName:"p"},"handleCustomOperator()")," method."),(0,a.kt)("p",null,"Let's take a look at the ",(0,a.kt)("inlineCode",{parentName:"p"},"handleListOperations")," method for simplicity:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-java"},'@SuppressWarnings("unchecked")\nprivate Token<?> handleListOperations(OperatorHandler handler, Map<Token<?>,Token<?>> original,\n                                        List<Token<?>> compare, OperatorToken operator,\n                                        CustomOperation customOp) {\n    Map<Token<?>, Token<?>> result;\n    if (handler.getOpType(operator) == OperatorType.SUBTRACT) {\n        /* Subtracts the matching keys present in the right-side list from the left-side map */\n        List<Token<?>> keysToRemove = original.keySet().stream()\n                .filter(compare::contains)\n                .collect(Collectors.toList());\n        keysToRemove.forEach(original::remove);\n        result = original;\n    } else {\n        result = (Map<Token<?>, Token<?>>) customOp.handleCustomOp();\n    }\n    return new MapToken(result);\n}\n')),(0,a.kt)("p",null,"In this case we are only supporting subtraction using an array as it we can use the key values found in an array\nto remove those from the Map. We simply loop through the key values filtering to only those which match the keys\nand then remove them from the resulting Map. Regarding operations, it is up to the choice of the developer as to\nwhether the original Map is updated but in this case we leave the state of the original Map alone and return a\nnew Map containing the result. If we wanted to reflect those changes back to the original map we would do:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"> myMap = {1->1,2->2,3->3}\n> myMap\nResult: {1->1,2->2,3->3}\n> myMap = myMap - [2]\n> myMap\nResult: {1->1,3->3}\n")),(0,a.kt)("p",null,"This operations class can then be registered in the config under the initTypeOperations() method:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-java"},"    private void initTypeOperations() {\n        //...\n        typeOperations.add(new MapOperation());\n    }\n")),(0,a.kt)("p",null,"With those registered, in addition to the above example we can now perform the following:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"> {1->1,2->2} + {3->3,4->4}\nResult: {1=1, 2=2, 3=3, 4=4}\n> {1->1,2->2,3->3} - {2->2}\nResult: {1=1, 3=3}\n")),(0,a.kt)("p",null,"In the above example the addition of the List containing keys is there to simplify the removal process. Otherwise by\nperforming a subtraction using two maps you would have to match both key and value. It is good to keep in mind what\nwould be useful to make writing expressions simple and as concise as possible."),(0,a.kt)("p",null,"*NOTE: This code is now included as part of the core SLOP functionality."))}u.isMDXComponent=!0}}]);